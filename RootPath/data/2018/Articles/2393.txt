https://mil.huanqiu.com/article/9CaKrnKaAg8
对人类威胁太大！2000科学家联名反对杀人机器人
来源：环球时报
2018-07-20 08:27
【环球网军事7月20日报道 环球时报记者 李司坤】好莱坞电影《终结者》为我们展现了杀手机器人横行、人类濒临灭绝的末日场景。随着近年来人工智能技术以及机器人技术的发展，此前还处于人们想象中的场景越来越接近现实，因而也愈发引起人们的警觉。
据英国《卫报》19日报道，由美国太空探索技术公司CEO马斯克以及谷歌顶级人工智能研究团队DeepMind创始人萨勒曼领衔的多家科技界大佬，与来自数百家公司的2000多名人工智能(AI)及机器人领域的科学家，在斯德哥尔摩国际AI联合会议上联名签署宣言，誓言绝不将他们的技能用于开发自主杀人机器。
该宣言表示，“我们签署者达成一致意见：永远不应将人类生命的决定权委托给机器”，“致命的自主武器，在没有人为干预的情况下选择和参与目标，将危及每个国家和个人的稳定。”通过该协议，签字者承诺今后将“既不参与也不支持致命自主武器的开发、制造、贸易或使用”。
报道称，各国军方是AI技术最大的资助和采购方。借助先进的计算机系统，机器人可以在各种地形上执行任务、在地面上巡逻或是在海上航行。而且“更复杂的武器系统正在筹备中”。《卫报》称，就在本周一，英国防长加文·威廉姆森公布一项价值20亿英镑的计划，确保新的英国空军战斗机“暴风雨”能在没有飞行员的情况下飞行。
美国国家公共电台称，这一承诺的立场在于最终鼓励全球政府采取法律行动。蒙特利尔学习算法研究所的AI领域先驱约书亚认为，如果该承诺能得到公众认可，舆论就会倒向他们。“这一做法已经在地雷问题上奏效了，”约书亚称，“尽管像美国这样的主要国家没有签署禁止地雷的条约，但美国的公司已经停止生产地雷。”
据了解，这已经不是AI届的领袖们第一次表达如上忧虑了。美国国家公共电台称，去年8月，各大科技企业的技术领导人就给联合国写了一封公开信，对围绕此类武器正在开展的军备竞赛提出警告。但问题是，仅靠科学家们的呼吁，人类社会能够避免打开智能杀人机器人这一潘多拉魔盒吗？
“有些问题是没办法去百分之百地阻止，因为发达国家都在研究如何将无人技术运用到军事领域，”19日在接受《环球时报》记者采访时，门罗机器人CEO杨兴义对这个问题并没有感到乐观，“在某些方面，科学家和军事部门之间并不是站在同一条战线上的，他们有时候是事物的正反两面。”
杨兴义认为，从技术层次上看，想要一劳永逸地杜绝人工智能朝着杀人机器的方向发展是很难的，“用什么方式能够控制自动武器去攻击谁是一件很难的事情，我们只能尽量约束它们开火的权力，比如设置代码或原则，把开火的权力控制在人类手上。”他表示，要防止人工智能技术朝着杀人机器的方向发展，更重要的是通过更多的法律、社会舆论和公众参与以及更多规则的建立来做到相互制约。
